{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Llama-3.2-11B-Vision Model\n",
    "\n",
    "This notebook downloads the complete Llama-3.2-11B-Vision repository as flat files to `$HOME/nfs_share/models` for offline access, with progress tracking and resume capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Set HuggingFace token (ensure HF_TOKEN environment variable is set)\\nif \\\"HF_TOKEN\\\" not in os.environ:\\n    raise ValueError(\\\"HF_TOKEN environment variable must be set\\\")\\n\\nprint(\\\"\u2705 HuggingFace token found in environment\\\")\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up destination directory\n",
    "home_dir = Path.home()\n",
    "model_dir = home_dir / \"nfs_share\" / \"models\" / \"Llama-3.2-11B-Vision\"\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\ud83d\ude80 Downloading complete Llama-3.2-11B-Vision repository\")\n",
    "print(f\"\ud83d\udcc1 Destination: {model_dir}\")\n",
    "print(\"\u23f1\ufe0f  This will download ~22GB of files...\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "try:\n",
    "    # Download complete repository as flat files\n",
    "    snapshot_download(\n",
    "        repo_id=\"meta-llama/Llama-3.2-11B-Vision\",\n",
    "        local_dir=str(model_dir),\n",
    "        resume_download=True,  # Resume if interrupted\n",
    "        local_files_only=False,  # Download from remote\n",
    "        # Skip .git files and save as flat files (no HF cache format)\n",
    "        ignore_patterns=[\"*.git*\", \"*.gitattributes\"],\n",
    "        cache_dir=None,  # Disable HuggingFace cache format\n",
    "    )\n",
    "\n",
    "    print(\"\\n\u2705 Download complete!\")\n",
    "    print(f\"\ud83d\udcc1 Model location: {model_dir}\")\n",
    "    print(\"\ud83c\udfaf Ready for offline access!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c Download failed: {e}\")\n",
    "    print(\"\ud83d\udca1 The download can be resumed by running this cell again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List downloaded files\n",
    "if model_dir.exists():\n",
    "    print(f\"\\n\ud83d\udccb Downloaded files:\")\n",
    "    for file in sorted(model_dir.rglob(\"*\")):\n",
    "        if file.is_file():\n",
    "            size_mb = file.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  {file.name}: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"\u274c Model directory not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}